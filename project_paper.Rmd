---
title: "Buoy Data"
author: "Gutierrez, Mena, Thompson, Silva"
date: "11/21/2021"
output: pdf_document
--- 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Import libraries ----
library(astsa)
library(fpp3)
library(readr)
library(lubridate)
knitr::opts_chunk$set(out.width = "65%", out.height="65%", fig.align="center", warning=FALSE, message=FALSE)
```

# Data Cleaning
```{r, echo=FALSE}
# Real time data (last 45 days)
#b_data <- read.table("https://www.ndbc.noaa.gov/data/realtime2/46268.txt")
#b_data <- read.table("https://www.ndbc.noaa.gov/data/realtime2/46268.txt")

# Load Data ----
#V1   2  3  4  5   6    7   8     9     10    11  12     13   14    15    16    17  18    19
#YY  MM DD hh mm WDIR WSPD GST  WVHT   DPD   APD MWD   PRES  ATMP  WTMP  DEWP  VIS PTDY  TIDE
#yr  mo dy hr mn degT m/s  m/s     m   sec   sec degT   hPa  degC  degC  degC  nmi  hPa    ft
b_data <- read.table("https://www.ndbc.noaa.gov/view_text_file.php?filename=46221h2020.txt.gz&dir=data/historical/stdmet/")
b_data19 <- read.table("https://www.ndbc.noaa.gov/view_text_file.php?filename=46221h2019.txt.gz&dir=data/historical/stdmet/")



#Format the dates using a Date Class
b_date <- paste(b_data[,1],"-",b_data[,2],"-",b_data[,3]," ",b_data[,4],":",b_data[,5]) 
b_date <- ymd_hm(b_date,tz = "UTC")
b_date19 <- paste(b_data19[,1],"-",b_data19[,2],"-",b_data19[,3]," ",b_data19[,4],":",b_data19[,5]) 
b_date19 <- ymd_hm(b_date19,tz = "UTC")

#7693 to 7694 is when the change of intervals happens 17:26 to 19:53
#15416 to 15417 is when the change of intervals happens 20:23 to 22:26
b_data %>% select(V9) -> data
data$time <- b_date
b_data19 %>% select(V9) -> data19
data19$time <- b_date19

# Attempt to fix the uneven time intervals as select times ----
testies<-data$time[7694:15416]
fixedTimes <- testies + minutes(3)
data$time[7694:15416] <- fixedTimes

testies19<-data19$time[1:9906]
fixedTimes19 <- testies19 - minutes(4)
data19$time[1:9906] <- fixedTimes19

#which((data$time[2:16184]-data$time[1:16183])>30)

newData <- rbind(data19,data)

# Turn into a tsibble ----
# using build_tsibble instead of as_tsibble to specify the interval  
buoy_ts <- build_tsibble(
  newData,
  key = dplyr::starts_with("2019-01-01 00:26:00"),
  index = time,
  ordered = TRUE,
  interval = new_interval(minute = 30),
  validate = TRUE
)


# Address additional missing data points (Maurico) ----
# TODO


# Count all the missing data and make them NA values
buoy_gaps <- buoy_ts %>%
  count_gaps(.full = TRUE)
buoy_ts <- buoy_ts %>% fill_gaps()

#Try fixing missing data using interpolate from ARIMA model---
buoy_fill <- buoy_ts %>% 
  model(ARIMA(V9 ~ pdq(4,1,0) + PDQ(2,0,0), approximation = FALSE)) %>%
  interpolate(buoy_ts)
```
Comments on our data cleaning process.

# Analysis

```{r, include=FALSE}
buoy_train <- buoy_fill %>% slice(5000:0- n()) # first 85% of buoy data
buoy_test <- buoy_fill %>% slice(n()- 5000:0) # last 15% of buoy data
```


We started the analysis by breaking the data up into separate training and testing sets. We did all of the initial analysis and model fitting exclusively on the training set. Doing this was important to ensure that we were able to test the models we have built using the training set by checking how well they forecast into the testing set that contains known observations. Keeping the testing set quarantined from the training set during the process is crucial.

## Transformations

Next, we plotted the data and tried to identify trend and non-constant variance. If either one is present in the data, the data will not be stationary which would require us to make some transformations to the data before we are able to proceed with model fitting. 

```{r, echo=FALSE}
autoplot(buoy_fill,V9)
```

```{r}
lambda <- buoy_train %>% 
  features(V9, features = guerrero) %>%
  pull(lambda_guerrero) ; lambda
```

```{r, echo=FALSE}
buoy_fill %>% 
  autoplot(box_cox(V9, lambda = lambda)) + 
  labs(y = "",
       title = latex2exp::TeX(paste0(
         "Transformed Buoy Data with $\\lambda$ = ",
         round(lambda,2))))

buoy_fill %>% autoplot(log(V9)) +
  labs(y = "",
       title = latex2exp::TeX(paste0(
         "Transformed Buoy Data with Log Transform")))
```

The data appears to have some non-constant variance with wildly varying magnitudes of lag heights throughout the two year period. To determine if a transformation is necessary, we performed a Box-Cox Test. The first thing we had to determine was an appropriate value for lambda to use in the Box Cox Test. For reference, $\lambda=1$ indicates no transformation is needed;  $\lambda=0.25$ indicates a fourth root transformation; and $\lambda=0$ indicates a log transformation is needed. Using a built in function in R, we determined that the suggest value is $\lambda = -0.00002945644$. Notice, that this value is extremely close to zero which suggests that using a simple log transformation is probably the best transformation to use. We plotted both transformations and found the two to be nearly identical. Thus, we decided to proceed with the rest analysis using a log transformation of the data. 

## Differencing

Once we determined that a log transformation was needed, we checked if the data needs to be diffferenced.

```{r, echo=FALSE}
buoy_train %>% gg_tsdisplay(log(V9),plot_type = "partial")

buoy_train %>% gg_tsdisplay(difference(log(V9)),plot_type = "partial")
```

The series appears level overall but the lags present in the ACF plot exhibit a very slow decay which indicates the data is nonstationary and should probably be differenced. Taking a single nonseasonal difference appears to have made the data stationary since there is no longer any slow decay in the ACF plot. There are also now lags with clear cutoffs and tailing behavior which is typically helpful in the model fitting process. If we choose to use a typical SARIMA model fitting, we now know we will need to use a model that has a nonseasonal difference order of $d=1$.

#  STL Decomposition

```{r, echo=FALSE}
#STL decomp ----
# Need to determine seaonal period(s)
lun_year <- 39000/30
lun_month <- (12*60+44+29*24*60)/30
lun_day <- (24+50/60)*2
sun_day <- 48
common_periods(buoy_fill)
buoy_fill %>%
  model(
    STL(log(V9) ~ season(period = lun_year)+       # 1 year
          season(period = lun_month)+  # months
          #season(period = 48*7)+   # weekly
          season(period = lun_day)+    # lunar daily
          season(period = sun_day),     # normal daily
        robust = TRUE)
  ) %>%
  components() %>%
  autoplot() + labs(x = "Observation")
```

comments - Daniel

# Model fitting
 comments on k selection and why DHR was choice.
 
```{r, echo=FALSE}
train_fitDHR <- model(buoy_train,
                      mk1 = ARIMA(log(V9) ~ PDQ(0,0,0)+pdq(d=0)+
                                    fourier(period = lun_year, K = 1)+
                                    fourier(period = lun_month, K = 1)),
                      mk2 = ARIMA(log(V9) ~ PDQ(0,0,0)+pdq(d=0)+
                                    fourier(period = lun_year, K = 2)+
                                    fourier(period = lun_month, K = 3)+
                                    fourier(period = lun_day, K = 2)),
                      mk3 = ARIMA(log(V9) ~ PDQ(0,0,0)+pdq(d=0)+
                                    fourier(period = lun_year, K = 1)+
                                    fourier(period = lun_month, K = 1)+
                                    fourier(period = sun_day, K = 2)),
                      mk4 = ARIMA(log(V9) ~ PDQ(0,0,0)+pdq(d=0)+
                                    fourier(period = lun_year, K = 3)+
                                    fourier(period = lun_month, K = 1)+
                                    fourier(period = lun_day, K = 2)+
                                    fourier(period = sun_day, K = 3)))
glance(train_fitDHR)
```

```{r}
# SARIMA model fit ----
sarima_fit <- buoy_train %>% model(auto = ARIMA(V9),
                           m1 = ARIMA(V9 ~ 0 + pdq(5,1,0) +PDQ(2,0,0,period = 24)),
                           m2 = ARIMA(V9 ~ 0 + pdq(4,1,0) +PDQ(2,0,0,period = 2)),
                           m3 = ARIMA(V9 ~ 0 + pdq(2,1,0) +PDQ(0,1,5,period = 16),
                                      order_constraint = p+q+P+Q<=10&(constant+d+D<=3)))

glance(sarima_fit)
```


# Residual Analysis

```{r, echo=FALSE}
train_fitDHR %>% select(mk1) %>% gg_tsresiduals(lag = 50)
train_fitDHR %>% select(mk2) %>% gg_tsresiduals(lag = 50)
train_fitDHR %>% select(mk3) %>% gg_tsresiduals(lag = 50)
train_fitDHR %>% select(mk4) %>% gg_tsresiduals(lag = 50)

augment(train_fitDHR) %>%
  features(.innov,ljung_box,lag=50)

#RMSE
  res1 <- residuals(train_fitDHR %>% select(mk1))
  res1 <- res1$.resid
  #MAE <- sum(abs(res))/length()
  RSS1 <- sum(res1^2)
  MSE1 <- RSS1/28071
  RMSE1 <- sqrt(MSE1)
  
  res2 <- residuals(train_fitDHR  %>% select(mk2))
  res2 <- res2$.resid
  #MAE <- sum(abs(res))/length()
  RSS2 <- sum(res2^2)
  MSE2 <- RSS2/28071
  RMSE2 <- sqrt(MSE2)
  
  res3 <- residuals(train_fitDHR  %>% select(mk3))
  res3 <- res3$.resid
  #MAE <- sum(abs(res))/length()
  RSS3 <- sum(res3^2)
  MSE3 <- RSS3/28071
  RMSE3 <- sqrt(MSE3)
  
  res4 <- residuals(train_fitDHR %>% select(mk4))
  res4 <- res4$.resid
  #MAE <- sum(abs(res))/length()
  RSS4 <- sum(res4^2)
  MSE4 <- RSS4/28071
  RMSE4 <- sqrt(MSE4)
  
  table_RMSE <- c(RMSE_mk1 = RMSE1,
                  RMSE_mk2 = RMSE2,
                  RMSE3_mk3 = RMSE3,
                  RMSE4_mk4 = RMSE4)
  table_RMSE
```
(i) Looking at all the count plot, the residuals from all models (mk1, mk2, mk3, mk4) are normally distributed and all have mean zero with only outlier present on each model located on the furthest right end of the plot.

(ii) All models appear to have constant variance, so we have nothing to be alarmed of.

(iii) In each ACF plot we have significant lags that appear at lags $h = 12, 17, 19, 38, 46, 47, 48$. Therefore, we have some significant autocorrelation that is most apparent every 6 hours.

(iv) Inspecting the AICc scores, model mk4 is the best model with the lowest AICc score of -80036.30. 
(v) The Ljung-Box test statistics all had very small p-values, meaning our residuals seem to not do well in forecasting these models. However, the model(s) that faired the best were mk1 and mk2. This means that we do not have sufficient evidence to reject our null hypothesis, that our residuals
appear to be correlated and could be improved.

(iv) All RMSE were all really close within one another, however the best model with the lowest RMSE (Root Mean Squared Error) is model mk4 with an RMSE value of 0.06904804. Minimizing this value, will result in forecasts of the mean.

# Forecast Testing

```{r, echo=FALSE}
buoy_TestFC_short <- train_fitDHR %>% forecast(h=12)

buoy_TestFC_mid <- train_fitDHR %>% forecast(h=336)

buoy_TestFC_long <- train_fitDHR %>% forecast(h=4036)

buoy_TestFC_short %>% autoplot(buoy_fill %>% slice(n()- 5300:0))  +
  labs(y = "Wave Hieght",
       title = "Short-Term Forecast for Substantial Wave Height") +
  guides(colour = guide_legend(title = "Forecast"))

buoy_TestFC_mid %>% autoplot(buoy_fill %>% slice(n()- 5300:0))  +
  labs(y = "Wave Hieght",
       title = "Mid-Term Forecast for Substantial Wave Height") +
  guides(colour = guide_legend(title = "Forecast"))

buoy_TestFC_long %>% autoplot(buoy_fill %>% slice(n()- 5300:0))  +
  labs(y = "Wave Hieght",
       title = "Long-Term Forecast for Substantial Wave Height") +
  guides(colour = guide_legend(title = "Forecast"))
```

Once we identified the best model fit to the training set, we tested the model's ability to forecast the training set. We forecasted a short term forecast (6 hours), mid-term forecast (1 week), and long-term forecast (3 month). In these plots, we only included about a week of data leading up to the forecat to give us a better scale for comparing the forecast against the testing set. The short is difficult to analyze since there are so few observations in the forecasts. The confidence intervals appear to contain all of the observations which is problematic. We expect to have on 95% of the data points in the confidence interval. The midterm and long term forecast have the same issue with the confidence intervals but they do appear to be giving a reasonable forecast of the wave height we would expect to see.

# Forecasting 
```{r, echo=FALSE}
best_fitDHR <-  model(buoy_fill,
                      mk3 = ARIMA(log(V9) ~ PDQ(0,0,0)+pdq(d=0)+
                                    fourier(period = lun_year, K = 1)+
                                    fourier(period = lun_month, K = 1)+
                                    fourier(period = sun_day, K = 2)))

buoy_FC_short <- best_fitDHR %>% forecast(h=12)

buoy_FC_mid <- best_fitDHR %>% forecast(h=336)

buoy_FC_long <- best_fitDHR%>% forecast(h=4036)

buoy_FC_short %>% autoplot(buoy_fill %>% slice(n()- 1440:0))  +
  labs(y = "Wave Hieght",
       title = "Short-Term Forecast for Substantial Wave Height") +
  guides(colour = guide_legend(title = "Forecast"))

buoy_FC_mid %>% autoplot(buoy_fill %>% slice(n()- 1440:0))  +
  labs(y = "Wave Hieght",
       title = "Mid-Term Forecast for Substantial Wave Height") +
  guides(colour = guide_legend(title = "Forecast"))

buoy_FC_long %>% autoplot(buoy_fill %>% slice(n()- 4036:0))  +
  labs(y = "Wave Hieght",
       title = "Long-Term Forecast for Substantial Wave Height") +
  guides(colour = guide_legend(title = "Forecast"))
```

For our actual forecast, we fit the model to the full data set including the both the training and test sets and then forecasted into the future. Theshort-term and mid-term forecast appears to be very reasonable. The long-term forecasts appears to really become unreliable after the the first week or so. This forecast is best for the shorter term forecasts.
